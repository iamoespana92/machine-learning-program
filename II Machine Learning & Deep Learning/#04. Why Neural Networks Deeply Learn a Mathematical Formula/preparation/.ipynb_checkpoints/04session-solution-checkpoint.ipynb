{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+5\">#07. Why Neural Networks Deeply Learn a Mathematical Formula?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Book + Private Lessons [Here ‚Üó](https://sotastica.com/reservar)\n",
    "- Subscribe to my [Blog ‚Üó](https://blog.pythonassembly.com/)\n",
    "- Let's keep in touch on [LinkedIn ‚Üó](www.linkedin.com/in/jsulopz) üòÑ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Machine Learning, what does it mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - The Machine Learns...\n",
    ">\n",
    "> But, **what does it learn?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Machine Learning, what does it mean? ‚èØ<br><br>¬∑ The machine learns...<br><br>Ha ha, not funny! ü§® What does it learn?<br><br>¬∑ A mathematical equation. For example: <a href=\"https://t.co/sjtq9F2pq7\">pic.twitter.com/sjtq9F2pq7</a></p>&mdash; Jes√∫s L√≥pez (@sotastica) <a href=\"https://twitter.com/sotastica/status/1449735653328031745?ref_src=twsrc%5Etfw\">October 17, 2021</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Machine Learning, what does it mean? ‚èØ<br><br>¬∑ The machine learns...<br><br>Ha ha, not funny! ü§® What does it learn?<br><br>¬∑ A mathematical equation. For example: <a href=\"https://t.co/sjtq9F2pq7\">pic.twitter.com/sjtq9F2pq7</a></p>&mdash; Jes√∫s L√≥pez (@sotastica) <a href=\"https://twitter.com/sotastica/status/1449735653328031745?ref_src=twsrc%5Etfw\">October 17, 2021</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does the Machine Learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In a Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Ht3rYS-JilE\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Ht3rYS-JilE\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=329\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=329\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Practical Example ‚Üí [Tesla Autopilot](https://www.tesla.com/AI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Example where It Fails ‚Üí [Tesla Confuses Moon with Semaphore](https://twitter.com/Carnage4Life/status/1418920100086784000?s=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Simply execute the following lines of code to load the data.\n",
    "> - This dataset contains **statistics about Car Accidents** (columns)\n",
    "> - In each one of **USA States** (rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/fivethirtyeight/fivethirtyeight-bad-drivers-dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NC</th>\n",
       "      <td>16.8</td>\n",
       "      <td>6.552</td>\n",
       "      <td>5.208</td>\n",
       "      <td>15.792</td>\n",
       "      <td>13.608</td>\n",
       "      <td>708.24</td>\n",
       "      <td>127.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NH</th>\n",
       "      <td>11.6</td>\n",
       "      <td>4.060</td>\n",
       "      <td>3.480</td>\n",
       "      <td>10.092</td>\n",
       "      <td>9.628</td>\n",
       "      <td>746.54</td>\n",
       "      <td>120.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KY</th>\n",
       "      <td>21.4</td>\n",
       "      <td>4.066</td>\n",
       "      <td>4.922</td>\n",
       "      <td>16.692</td>\n",
       "      <td>16.264</td>\n",
       "      <td>872.51</td>\n",
       "      <td>137.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LA</th>\n",
       "      <td>20.5</td>\n",
       "      <td>7.175</td>\n",
       "      <td>6.765</td>\n",
       "      <td>14.965</td>\n",
       "      <td>20.090</td>\n",
       "      <td>1281.55</td>\n",
       "      <td>194.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MD</th>\n",
       "      <td>12.5</td>\n",
       "      <td>4.250</td>\n",
       "      <td>4.000</td>\n",
       "      <td>8.875</td>\n",
       "      <td>12.375</td>\n",
       "      <td>1048.78</td>\n",
       "      <td>192.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                       \n",
       "NC       16.8     6.552    5.208          15.792       13.608       708.24   \n",
       "NH       11.6     4.060    3.480          10.092        9.628       746.54   \n",
       "KY       21.4     4.066    4.922          16.692       16.264       872.51   \n",
       "LA       20.5     7.175    6.765          14.965       20.090      1281.55   \n",
       "MD       12.5     4.250    4.000           8.875       12.375      1048.78   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "NC          127.82  \n",
       "NH          120.21  \n",
       "KY          137.13  \n",
       "LA          194.78  \n",
       "MD          192.70  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset(name='car_crashes', index_col='abbrev')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Concepts in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the `Weights`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - https://keras.io/api/layers/initializers/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to `kernel_initializer` the weights?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "accidents = speeding \\cdot w_1 + alcohol \\cdot w_2 \\ + ... + \\ ins\\_losses \\cdot w_7\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, Input\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 7)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='zeros'))\n",
    "model.add(layer=Dense(units=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a Prediction with the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Can we make a prediction for for `Washington DC` accidents\n",
    "> - With the already initialized Mathematical Equation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='total')\n",
    "y = df.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL = X[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>7.332</td>\n",
       "      <td>5.64</td>\n",
       "      <td>18.048</td>\n",
       "      <td>15.04</td>\n",
       "      <td>784.55</td>\n",
       "      <td>145.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                \n",
       "AL         7.332     5.64          18.048        15.04       784.55   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "AL          145.08  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observe the numbers for the `weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[-0.5762638],\n",
       "        [-0.2094115],\n",
       "        [ 0.6208321]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `fit()` the `model` and compare again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 220.0011 - mse: 220.0011\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 79.4821 - mse: 79.4821\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 43.6494 - mse: 43.6494\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 31.4360 - mse: 31.4360\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.1127 - mse: 28.1127\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.8386 - mse: 27.8386\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.2768 - mse: 27.2768\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.1060 - mse: 27.1060\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 26.8111 - mse: 26.8111\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.5435 - mse: 26.5435\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.3563 - mse: 26.3563\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.2157 - mse: 26.2157\n",
      "Epoch 13/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 26.4067 - mse: 26.4067"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 15:58:00.117199: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 25.9490 - mse: 25.9490\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.2238 - mse: 26.2238\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.2046 - mse: 26.2046\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.1636 - mse: 25.1636\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.1110 - mse: 25.1110\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.5164 - mse: 28.5164\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.6732 - mse: 25.6732\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 24.0052 - mse: 24.0052\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 25.2208 - mse: 25.2208\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 26.9832 - mse: 26.9832\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.7166 - mse: 23.7166\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 24.1376 - mse: 24.1376\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 24.9666 - mse: 24.9666\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 24.4440 - mse: 24.4440\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.4342 - mse: 22.4342\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.1445 - mse: 22.1445\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.8834 - mse: 21.8834\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.1140 - mse: 21.1140\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.6880 - mse: 21.6880\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.1284 - mse: 22.1284\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 20.3375 - mse: 20.3375\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 22.3228 - mse: 22.3228\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 20.8170 - mse: 20.8170\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 19.5477 - mse: 19.5477\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 20.0771 - mse: 20.0771\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 22.5508 - mse: 22.5508\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.9076 - mse: 19.9076\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.6752 - mse: 18.6752\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.5202 - mse: 18.5202\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.4625 - mse: 19.4625\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.5634 - mse: 17.5634\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 17.6254 - mse: 17.6254\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.9341 - mse: 18.9341\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.7214 - mse: 17.7214\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.9448 - mse: 18.9448\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.9663 - mse: 16.9663\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.1362 - mse: 18.1362\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.0106 - mse: 17.0106\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.8229 - mse: 18.8229\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.0845 - mse: 16.0845\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 16.7973 - mse: 16.7973\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.9566 - mse: 14.9566\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.2885 - mse: 15.2885\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.2724 - mse: 18.2724\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.4652 - mse: 15.4652\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.3117 - mse: 14.3117\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.3152 - mse: 16.3152\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.5006 - mse: 14.5006\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.6306 - mse: 13.6306\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.4643 - mse: 15.4643\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.5777 - mse: 14.5777\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.9077 - mse: 12.9077\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.6927 - mse: 12.6927\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.5016 - mse: 12.5016\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.9885 - mse: 12.9885\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.0649 - mse: 12.0649\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.7856 - mse: 13.7856\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.8783 - mse: 11.8783\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.4151 - mse: 11.4151\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.8627 - mse: 11.8627\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.7514 - mse: 12.7514\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.7902 - mse: 10.7902\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.5657 - mse: 10.5657\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.0313 - mse: 11.0313\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.2313 - mse: 10.2313\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.0720 - mse: 10.0720\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.7880 - mse: 9.7880\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.0303 - mse: 12.0303\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.1977 - mse: 13.1977\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.8383 - mse: 10.8383\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.2575 - mse: 9.2575\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.4634 - mse: 9.4634\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.6148 - mse: 10.6148\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.1634 - mse: 10.1634\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7602 - mse: 8.7602\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.2230 - mse: 8.2230\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.0587 - mse: 8.0587\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.9578 - mse: 7.9578\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.8348 - mse: 9.8348\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.1733 - mse: 8.1733\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.4719 - mse: 7.4719\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.5647 - mse: 8.5647\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2513 - mse: 7.2513\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.0042 - mse: 8.0042\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.8788 - mse: 8.8788\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.7501 - mse: 6.7501\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.9239 - mse: 8.9239\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.6815 - mse: 7.6815\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.6931 - mse: 6.6931\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.2463 - mse: 6.2463\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.8226 - mse: 7.8226\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.5189 - mse: 11.5189\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.9989 - mse: 6.9989\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.8508 - mse: 5.8508\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.8366 - mse: 5.8366\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.8243 - mse: 5.8243\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.7327 - mse: 5.7327\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5.5821 - mse: 5.5821\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.4647 - mse: 5.4647\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.2097 - mse: 5.2097\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.0708 - mse: 5.0708\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.8583 - mse: 4.8583\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 6.6078 - mse: 6.6078\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.7145 - mse: 6.7145\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.9225 - mse: 5.9225\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.5959 - mse: 7.5959\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.9932 - mse: 5.9932\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.5285 - mse: 4.5285\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.6132 - mse: 4.6132\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.4857 - mse: 4.4857\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.0977 - mse: 5.0977\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.6631 - mse: 5.6631\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.4285 - mse: 4.4285\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.0005 - mse: 5.0005\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1719 - mse: 4.1719\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.2526 - mse: 4.2526\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.2498 - mse: 4.2498\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.7009 - mse: 5.7009\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.4791 - mse: 6.4791\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.7734 - mse: 3.7734\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.7538 - mse: 3.7538\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.7769 - mse: 3.7769\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.9815 - mse: 3.9815\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.2948 - mse: 4.2948\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.9303 - mse: 3.9303\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.0552 - mse: 4.0552\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.0937 - mse: 7.0937\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1342 - mse: 4.1342\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.2890 - mse: 4.2890\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.4951 - mse: 4.4951\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.1136 - mse: 3.1136\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.2323 - mse: 3.2323\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.0068 - mse: 4.0068\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.9905 - mse: 2.9905\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.9721 - mse: 2.9721\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.9148 - mse: 3.9148\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.2394 - mse: 3.2394\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.9852 - mse: 2.9852\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.9619 - mse: 4.9619\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1056 - mse: 4.1056\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.7310 - mse: 2.7310\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 3.2935 - mse: 3.2935\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 4.5884 - mse: 4.5884\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.7821 - mse: 4.7821\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.1755 - mse: 4.1755\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.4276 - mse: 3.4276\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.5844 - mse: 2.5844\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.7058 - mse: 2.7058\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 4.9107 - mse: 4.9107\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 5.1864 - mse: 5.1864\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7327 - mse: 2.7327\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.4554 - mse: 2.4554\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.5073 - mse: 2.5073\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.5413 - mse: 4.5413\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.6372 - mse: 4.6372\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.9187 - mse: 2.9187\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8886 - mse: 2.8886\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.0184 - mse: 4.0184\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8371 - mse: 2.8371\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.2966 - mse: 2.2966\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.6694 - mse: 2.6694\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.8862 - mse: 4.8862\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.7958 - mse: 3.7958\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.9953 - mse: 3.9953\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.5714 - mse: 2.5714\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.2744 - mse: 2.2744\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.2187 - mse: 2.2187\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.3302 - mse: 2.3302\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.2172 - mse: 2.2172\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.2874 - mse: 3.2874\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.9755 - mse: 3.9755\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.3130 - mse: 3.3130\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.3460 - mse: 2.3460\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0762 - mse: 2.0762\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.7882 - mse: 2.7882\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.9419 - mse: 4.9419\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.6915 - mse: 3.6915\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.6051 - mse: 3.6051\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.3606 - mse: 2.3606\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0798 - mse: 2.0798\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.0768 - mse: 3.0768\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.5791 - mse: 2.5791\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.1403 - mse: 2.1403\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.2923 - mse: 3.2923\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1216 - mse: 4.1216\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.4898 - mse: 2.4898\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.7506 - mse: 2.7506\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.4170 - mse: 2.4170\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.9334 - mse: 1.9334\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.9172 - mse: 1.9172\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7498 - mse: 2.7498\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.5014 - mse: 5.5014\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.0656 - mse: 4.0656\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.4922 - mse: 2.4922\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9293 - mse: 1.9293\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0516 - mse: 2.0516\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.9608 - mse: 1.9608\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.9583 - mse: 1.9583\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8435 - mse: 1.8435\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8294 - mse: 1.8294\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.5322 - mse: 2.5322\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.9832 - mse: 6.9832\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.9073 - mse: 3.9073\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.4899 - mse: 2.4899\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.1603 - mse: 2.1603\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0586 - mse: 2.0586\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9626 - mse: 1.9626\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0693 - mse: 2.0693\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.7354 - mse: 4.7354\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.8191 - mse: 4.8191\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.6248 - mse: 2.6248\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9366 - mse: 1.9366\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0676 - mse: 2.0676\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.4921 - mse: 2.4921\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.6450 - mse: 2.6450\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.3634 - mse: 2.3634\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.7377 - mse: 1.7377\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7297 - mse: 1.7297\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.3315 - mse: 2.3315\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.0201 - mse: 5.0201\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.7753 - mse: 3.7753\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7083 - mse: 1.7083\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.7744 - mse: 2.7744\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.1703 - mse: 3.1703\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.6841 - mse: 1.6841\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6790 - mse: 1.6790\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7105 - mse: 1.7105\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6696 - mse: 1.6696\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.1074 - mse: 2.1074\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8086 - mse: 2.8086\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9353 - mse: 1.9353\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6953 - mse: 1.6953\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.9503 - mse: 1.9503\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.1535 - mse: 5.1535\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.2533 - mse: 3.2533\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.7616 - mse: 1.7616\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0066 - mse: 2.0066\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.6902 - mse: 2.6902\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.4157 - mse: 2.4157\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.6154 - mse: 1.6154\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.6102 - mse: 1.6102\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5985 - mse: 1.5985\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.5659 - mse: 2.5659\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.8613 - mse: 3.8613\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.0184 - mse: 3.0184\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.2062 - mse: 2.2062\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5936 - mse: 1.5936\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.8192 - mse: 2.8192\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.3579 - mse: 3.3579\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.6001 - mse: 1.6001\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.8442 - mse: 1.8442\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.5765 - mse: 1.5765\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5913 - mse: 1.5913\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5752 - mse: 1.5752\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.1719 - mse: 3.1719\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.7295 - mse: 2.7295\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.7774 - mse: 3.7774\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.6600 - mse: 2.6600\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6316 - mse: 1.6316\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.2992 - mse: 2.2992\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.3159 - mse: 2.3159\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.6823 - mse: 1.6823\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5462 - mse: 1.5462\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6587 - mse: 1.6587\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.9236 - mse: 1.9236\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.1258 - mse: 2.1258\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0489 - mse: 2.0489\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.6808 - mse: 2.6808\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.3671 - mse: 6.3671\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.2163 - mse: 2.2163\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8342 - mse: 1.8342\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5394 - mse: 1.5394\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9976 - mse: 1.9976\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.4824 - mse: 2.4824\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.2336 - mse: 3.2336\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.3312 - mse: 2.3312\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 3.4521 - mse: 3.4521\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.8163 - mse: 2.8163\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.5526 - mse: 2.5526\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.1214 - mse: 2.1214\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.5641 - mse: 3.5641\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.4599 - mse: 2.4599\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0262 - mse: 2.0262\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.0560 - mse: 2.0560\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7286 - mse: 1.7286\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5178 - mse: 1.5178\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.6756 - mse: 1.6756\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7437 - mse: 2.7437\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.0097 - mse: 3.0097\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.4692 - mse: 3.4692\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.3368 - mse: 4.3368\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.3811 - mse: 2.3811\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7542 - mse: 2.7542\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.4283 - mse: 2.4283\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.4721 - mse: 2.4721\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.6047 - mse: 1.6047\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.6369 - mse: 1.6369\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.4636 - mse: 2.4636\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.7859 - mse: 2.7859\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.5739 - mse: 1.5739\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.6071 - mse: 1.6071\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4509 - mse: 1.4509\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0750 - mse: 2.0750\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.0206 - mse: 2.0206\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.9039 - mse: 2.9039\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.3869 - mse: 2.3869\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.6378 - mse: 2.6378\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.5424 - mse: 4.5424\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9051 - mse: 1.9051\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4591 - mse: 1.4591\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6059 - mse: 1.6059\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.5770 - mse: 2.5770\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.2760 - mse: 2.2760\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.6730 - mse: 1.6730\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.5340 - mse: 4.5340\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.8108 - mse: 3.8108\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.9363 - mse: 1.9363\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.5815 - mse: 1.5815\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.4521 - mse: 1.4521\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.8358 - mse: 1.8358\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.4322 - mse: 2.4322\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8663 - mse: 2.8663\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.2313 - mse: 3.2313\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6616 - mse: 1.6616\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7258 - mse: 1.7258\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4332 - mse: 1.4332\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6354 - mse: 1.6354\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0760 - mse: 2.0760\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.9070 - mse: 1.9070\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3893 - mse: 1.3893\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.5144 - mse: 2.5144\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.5223 - mse: 4.5223\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.5056 - mse: 2.5056\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.9052 - mse: 1.9052\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.8821 - mse: 1.8821\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.4866 - mse: 1.4866\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.5367 - mse: 1.5367\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7293 - mse: 1.7293\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.4176 - mse: 4.4176\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.5538 - mse: 4.5538\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6560 - mse: 1.6560\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.4157 - mse: 1.4157\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9314 - mse: 1.9314\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.6390 - mse: 2.6390\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 3.0639 - mse: 3.0639\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5217 - mse: 1.5217\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4246 - mse: 1.4246\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7439 - mse: 1.7439\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.8423 - mse: 3.8423\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8860 - mse: 1.8860\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.4244 - mse: 1.4244\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5683 - mse: 1.5683\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.4059 - mse: 1.4059\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.5780 - mse: 1.5780\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.3802 - mse: 2.3802\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.2414 - mse: 4.2414\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.2252 - mse: 2.2252\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9165 - mse: 1.9165\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.9580 - mse: 1.9580\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4079 - mse: 1.4079\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3604 - mse: 1.3604\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4800 - mse: 1.4800\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.9248 - mse: 2.9248\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.0389 - mse: 3.0389\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.4514 - mse: 2.4514\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9963 - mse: 1.9963\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8446 - mse: 1.8446\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.5327 - mse: 2.5327\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.0852 - mse: 2.0852\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.5023 - mse: 1.5023\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.4504 - mse: 2.4504\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.3555 - mse: 3.3555\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8170 - mse: 1.8170\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.9370 - mse: 1.9370\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.7817 - mse: 2.7817\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.9958 - mse: 2.9958\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6665 - mse: 1.6665\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3909 - mse: 1.3909\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3472 - mse: 1.3472\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3311 - mse: 1.3311\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9233 - mse: 1.9233\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.5948 - mse: 5.5948\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.4850 - mse: 2.4850\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.3520 - mse: 1.3520\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3196 - mse: 1.3196\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.3380 - mse: 1.3380\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6951 - mse: 1.6951\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.1948 - mse: 3.1948\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8111 - mse: 1.8111\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3280 - mse: 1.3280\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3183 - mse: 1.3183\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9979 - mse: 1.9979\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.9831 - mse: 4.9831\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.6813 - mse: 2.6813\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5207 - mse: 1.5207\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5645 - mse: 1.5645\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9210 - mse: 1.9210\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4994 - mse: 1.4994\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.2247 - mse: 3.2247\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.3138 - mse: 2.3138\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.4859 - mse: 1.4859\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3737 - mse: 1.3737\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6182 - mse: 1.6182\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.6145 - mse: 3.6145\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.5697 - mse: 2.5697\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4709 - mse: 1.4709\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0998 - mse: 2.0998\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.0940 - mse: 4.0940\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8323 - mse: 2.8323\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.3827 - mse: 2.3827\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4470 - mse: 1.4470\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.3021 - mse: 1.3021\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4488 - mse: 1.4488\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.0681 - mse: 2.0681\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.1064 - mse: 3.1064\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8465 - mse: 2.8465\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4208 - mse: 1.4208\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7360 - mse: 1.7360\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.3515 - mse: 5.3515\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.5171 - mse: 2.5171\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3383 - mse: 1.3383\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3145 - mse: 1.3145\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6770 - mse: 1.6770\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3985 - mse: 1.3985\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2754 - mse: 1.2754\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4617 - mse: 1.4617\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.7495 - mse: 4.7495\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.2686 - mse: 3.2686\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.4082 - mse: 2.4082\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3453 - mse: 1.3453\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.7151 - mse: 1.7151\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0412 - mse: 2.0412\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3869 - mse: 1.3869\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5829 - mse: 1.5829\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3694 - mse: 1.3694\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3059 - mse: 1.3059\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8915 - mse: 1.8915\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.3221 - mse: 4.3221\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.1298 - mse: 3.1298\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4864 - mse: 1.4864\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3855 - mse: 1.3855\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.1554 - mse: 2.1554\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.4329 - mse: 2.4329\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8629 - mse: 1.8629\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4562 - mse: 1.4562\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2655 - mse: 1.2655\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4333 - mse: 1.4333\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.0709 - mse: 3.0709\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.3011 - mse: 4.3011\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.2166 - mse: 2.2166\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.2017 - mse: 3.2017\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.5596 - mse: 2.5596\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3373 - mse: 1.3373\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2828 - mse: 1.2828\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2292 - mse: 1.2292\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4910 - mse: 1.4910\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.5201 - mse: 3.5201\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.3840 - mse: 2.3840\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4686 - mse: 1.4686\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.6584 - mse: 1.6584\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8273 - mse: 1.8273\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3542 - mse: 1.3542\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2844 - mse: 1.2844\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.9335 - mse: 1.9335\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.9078 - mse: 3.9078\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7490 - mse: 1.7490\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5374 - mse: 1.5374\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.5556 - mse: 1.5556\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.6127 - mse: 1.6127\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.6746 - mse: 2.6746\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.5752 - mse: 2.5752\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.8713 - mse: 3.8713\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7361 - mse: 2.7361\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5179 - mse: 1.5179\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4647 - mse: 1.4647\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2175 - mse: 1.2175\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.9299 - mse: 1.9299\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.6478 - mse: 2.6478\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.3466 - mse: 2.3466\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2192 - mse: 1.2192\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9506 - mse: 1.9506\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.5841 - mse: 3.5841\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.6745 - mse: 3.6745\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5179 - mse: 1.5179\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2212 - mse: 1.2212\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2854 - mse: 1.2854\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.1924 - mse: 1.1924\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5223 - mse: 1.5223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ca2d50a0>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=500, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observe the numbers for the `weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 15:58:06.582812: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>17.773069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>16.825064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>17.085932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>20.903179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>11.900213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8   17.773069\n",
       "AK       18.1   16.825064\n",
       "AZ       18.6   17.085932\n",
       "AR       22.4   20.903179\n",
       "CA       12.0   11.900213"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros_after_fit'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5867405561780896"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to `kernel_initializer` the weights to 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to `kernel_initializer` the weights to `glorot_uniform` (default)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with the Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - https://keras.io/api/layers/activations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=558\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=558\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `sigmoid` activation in last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='glorot_uniform'))\n",
    "model.add(layer=Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `fit()` the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 15:58:06.766258: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ae261b20>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 15:58:10.991217: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8         1.0\n",
       "AK       18.1         1.0\n",
       "AZ       18.6         1.0\n",
       "AR       22.4         1.0\n",
       "CA       12.0         1.0"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235.4076470588235"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observe the numbers for the `weights`\n",
    "\n",
    "> - Have they changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.10580671,  0.7500808 ,  0.16253507],\n",
       "        [-0.34526154, -0.5762522 , -0.7753689 ],\n",
       "        [-0.29335958, -0.2159903 , -0.16609263],\n",
       "        [ 0.26099467,  0.28944385, -0.42102963],\n",
       "        [-0.25016683,  0.3994559 , -0.5259208 ],\n",
       "        [ 0.22661805,  0.02153301,  0.28560925]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[-1.1483067 ],\n",
       "        [-0.9938561 ],\n",
       "        [-0.47182316]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `linear` activation in last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `tanh` activation in last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `relu` activation in last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How are the predictions changing? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - https://keras.io/api/optimizers/#available-optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizers comparison in GIF ‚Üí https://mlfromscratch.com/optimizers-explained/#adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tesla's Neural Network Models is composed of 48 models trainned in 70.000 hours of GPU ‚Üí https://tesla.com/ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Year with a 8 GPU Computer ‚Üí https://twitter.com/thirdrowtesla/status/1252723358342377472"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Gradient Descent `SGD`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile & Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='glorot_uniform'))\n",
    "model.add(layer=Dense(units=1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.6810684 , -0.5374545 ,  0.3188858 ],\n",
       "        [-0.39073986, -0.02681237, -0.60462564],\n",
       "        [-0.46303684,  0.35544014,  0.5196427 ],\n",
       "        [ 0.4338212 , -0.7204268 , -0.38986075],\n",
       "        [ 0.1456449 ,  0.14355439, -0.3317555 ],\n",
       "        [-0.40201446,  0.52149   ,  0.09402621]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[-0.00162935],\n",
       "        [-0.8344277 ],\n",
       "        [-1.132802  ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 15:58:41.068801: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-11-16 15:58:41.139279: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, epochs=500, verbose=0, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan]], dtype=float32),\n",
       " array([nan, nan, nan], dtype=float32),\n",
       " array([[nan],\n",
       "        [nan],\n",
       "        [nan]], dtype=float32),\n",
       " array([-1.2005279e+28], dtype=float32)]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 15:58:50.613774: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8         0.0\n",
       "AK       18.1         0.0\n",
       "AZ       18.6         0.0\n",
       "AR       22.4         0.0\n",
       "CA       12.0         0.0"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265.9880392156863"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### View History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `ADAM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `RMSPROP`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does it take different times to get the best accuracy? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - https://keras.io/api/losses/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `binary_crossentropy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `sparse_categorical_crossentropy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `mean_absolute_error`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `mean_squared_error`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the end, what should be a feasible configuration of the Neural Network for this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `kernel_initializer` Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `activation` Function Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `optimizer` Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Number of `epochs` Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `loss` Function Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Number of `epochs` Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network's importance to find **Non-Linear Patterns** in the Data\n",
    "\n",
    "> - The number of Neurons & Hidden Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/beginners-ask-how-many-hidden-layers-neurons-to-use-in-artificial-neural-networks-51466afa0d3e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.87287&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Mathematical Formula\n",
    "- Weights / Kernel Initializer\n",
    "- Loss Function\n",
    "- Activation Function\n",
    "- Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What cannot you change arbitrarily of a Neural Network?\n",
    "\n",
    "- Input Neurons\n",
    "- Output Neurons\n",
    "- Loss Functions\n",
    "- Activation Functions"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Jes√∫s L√≥pez @sotastica"
   }
  ],
  "kernelspec": {
   "display_name": "Deep Learning Python",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

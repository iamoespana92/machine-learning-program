{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+5\">#04. Model Selection. Decision Tree vs Support Vector Machines vs Logistic Regression</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Doubts? → Ask me in <img src=\"https://emoji.gg/assets/emoji/3970-discord.png\" style=\"height: 1em; vertical-align: middle;\"> <a href=\"https://discord.gg/cmB3KGsqMy\">Discord</a></li>\n",
    "    <li>Tutorials → <img src=\"https://openmoji.org/php/download_asset.php?type=emoji&emoji_hexcode=E044&emoji_variant=color\" style=\"height: 1em; vertical-align: middle;\"> <a href=\"https://www.youtube.com/channel/UCovCte2I3loteQE_kRsfQcw\">YouTube</a></li>\n",
    "    <li>Book Private Lessons → <span style=\"color: orange\">@</span> <a href=\"https://sotastica.com/reservar\">sotastica</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset from [CIS](https://www.cis.es/cis/opencms/ES/index.html) executing the lines of code below:\n",
    "> - The goal of this dataset is\n",
    "> - To predict `internet_usage` of **people** (rows)\n",
    "> - Based on their **socio-demographical characteristics** (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>internet_usage</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>66</td>\n",
       "      <td>Elementary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>72</td>\n",
       "      <td>Elementary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>48</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>59</td>\n",
       "      <td>PhD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>44</td>\n",
       "      <td>PhD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   internet_usage     sex  age   education\n",
       "0               0  Female   66  Elementary\n",
       "1               1    Male   72  Elementary\n",
       "2               1    Male   48  University\n",
       "3               0    Male   59         PhD\n",
       "4               1  Female   44         PhD"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/py-thocrates/data/main/internet_usage_spain.csv'\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `DecisionTreeClassifier()` Model in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Vamos a aplicar la lógica natural que hemos seguido durante todo el programa. Por tanto, los pasos a seguir son:\n",
    "\n",
    "```python\n",
    "model.fit() # calcular los mejores números en la ecuación matemática\n",
    "model.score() # calcular cómo de bueno es el modelo: Realidad vs Predicción\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to Automate Lines of Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> El objetivo de este capítulo es comprender cómo se comparan los diferentes modelos de ML. En este punto concreto del programa, deberíamos saber que los modelos siempre funcionan igual:\n",
    "\n",
    "```python\n",
    "model.fit() # calcular los mejores números en la ecuación matemática\n",
    "model.score() # calcular cómo de bueno es el modelo: Realidad vs Predicción\n",
    "```\n",
    "\n",
    "> El modelo a usar es lo único que cambiaría. Por tanto, nos preguntamos lo siguiente: ¿por qué no **crear una función** que te calcule las predicciones directamente al **pasarle un modelo**, como `parametro`? De esta forma podríamos ejecutar las siguientes líneas y entrenar todos los modelos con la misma función.\n",
    "\n",
    "```python\n",
    "dt = DecisionTreeClassifier()\n",
    "calcular_precision(model=dt)\n",
    "\n",
    "svm = SVC()\n",
    "calcular_precision(model=svm)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "calcular_precision(model = lr)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `DecisionTreeClassifier()` Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `SVC()` Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `LogisticRegression()` Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which is the Best Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Which model has the **highest accuracy**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## University Access Exams Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's **imagine**:\n",
    ">\n",
    "> 1. You have a `math exam` on Saturday\n",
    "> 2. Today is Monday\n",
    "> 3. You want to **calculate if you need to study more** for the math exam\n",
    "> 4. How do you calibrate your `math level`?\n",
    "> 5. Well, you've got **100 questions `X` with 100 solutions `y`** from past years exams\n",
    "> 6. You may study the 100 questions with 100 solutions `fit(questions, solutions)`\n",
    "> 7. Then, you may do a `mock exam` with the 100 questions `predict(questions)`\n",
    "> 8. And compare `your_solutions` with the `real_solutions`\n",
    "> 9. You've got **90/100 correct answers** `accuracy` in the mock exam\n",
    "> 10. You think you are **prepared for the maths exam**\n",
    "> 11. And when you do **the real exam on Saturday, the mark is 40/100**\n",
    "> 12. Why? How could have we prevented this?\n",
    "> 13. **Solution**: separate the 100 questions in\n",
    "> - `70 train` to study & `30 test` for the mock exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separar Datos en Train & Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **1. Entrenar Modelo con Train**\n",
    ">\n",
    "> Al separar los datos en `Entreno` y `Testeo` nos encontraríamos en el siguiente supuesto según la analogía del examen de selectividad:\n",
    ">\n",
    "> Estudiamos/Entrenamos `.fit()` para el examen con 70 preguntas `X_train` y respectivas 70 soluciones `y_train`.\n",
    ">\n",
    "> - `model.fit(X_train, y_train)`\n",
    ">\n",
    "> **2. Realizar Predicciones en Test**\n",
    ">\n",
    "> Hacemos un examen `.predict()` de mentira **sin ver las soluciones `y_test`**. Tan solo con lo que sabemos de antes y las **30 nuevas preguntas que no vimos `X_test`** durante el estudio/entrenamiento.\n",
    ">\n",
    "> - `y_pred = model.predict(X_test)`\n",
    ">\n",
    "> **3. Comparar Predicciones vs Realidad de Test**\n",
    ">\n",
    "> Por último veríamos cómo de preparados estamos para el examen de selectividad al comprobar si las respuestas que hemos desarrollado `y_pred` coinciden con las soluciones reales `y_test`.\n",
    ">\n",
    "> - `y_pred == y_test`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizar Modelos y Comparar Otra Vez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ahora deberíamos entrenar un modelo aplicando la lógica que acabamos de exponer: ajustamos la ecuación matemática con los datos de entrenamiento y comprobamos **cómo de bueno es el modelo en los datos de testeo**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de Árboles de Decisión con Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Deberíamos obtener la precisión del `DecisionTreeClassifier()` con los datos de `Testeo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de Support Vector Machine con Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Deberíamos obtener la precisión del `SVC()` con los datos de `Testeo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de Regresión Logística con Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Deberíamos obtener la precisión del `LogisticRegression()` con los datos de `Testeo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Cuál es el Mejor Modelo con Train Test Split?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tomamos la decisión con el modelo que haya tenido mayor precisión porque nos indicaría que ha acertado más veces la realidad en los datos de `Testeo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La Importancia del Remuestreo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Las métricas nos dicen ahora que el mejor modelo es otro...\n",
    ">\n",
    "> Qué hubiera pasado si, por cada centésima de fallo `0.01` en datos que no conoce, perdemos 1 Millón de Euros. No sabría deciros en vuestro caso, pero con lo que da la diferencia yo me retiro...\n",
    ">\n",
    "> Los modelos pueden ser muy buenos en datos que conocen de antemano durante el entrenamiento. Sin embargo, quisiéramos emplear el modelo en datos que no conoció durante el entrenamiento (predecir si un cliente futuro afrontará un préstamo).\n",
    ">\n",
    "> El hecho de haber calibrado nuestro modelo, de ver lo bueno que es nuestro modelo en datos que no conoció **(Test)** durante el entrenamiento **(Train)** hace que nos fiemos mejor de su rendimiento frente a datos que no conoce.\n",
    ">\n",
    "> Por tanto, la técnica `train test split` debemos usarla siempre que queramos calibrar cómo de bueno es nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Jesús López @sotastica"
   }
  ],
  "interpreter": {
   "hash": "414fd6d7c0f0aefb3d4e2db41edbeb0df03134e10d94a689550561b640a17652"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
